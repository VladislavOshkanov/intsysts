{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_train, df_test):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train : pandas Dataframe\n",
    "    df_test : pandas Dataframe\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    df_train : pandas Dataframe\n",
    "    df_test : pandas Dataframe\n",
    "    y_train : pandas Series\n",
    "    '''\n",
    "    # remove outliers in GrLivArea\n",
    "    df_train.drop(df_train[df_train['GrLivArea'] > 4500].index, inplace=True)   \n",
    "\n",
    "    # Normalize SalePrice using log_transform\n",
    "    y_train = np.log1p(df_train['SalePrice'])\n",
    "    # Remove SalePrice from training and merge training and test data\n",
    "    df_train.pop('SalePrice')\n",
    "    dataset = pd.concat([df_train, df_test])\n",
    "\n",
    "    # Numerical variable with \"categorical meaning\"\n",
    "    # Cast it to str so that we get dummies later on\n",
    "    dataset['MSSubClass'] = dataset['MSSubClass'].astype(str)\n",
    "\n",
    "    \n",
    "    ### filling NaNs ###\n",
    "    # no alley\n",
    "    dataset[\"Alley\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # no basement\n",
    "    dataset[\"BsmtCond\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"BsmtExposure\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"BsmtFinSF1\"].fillna(0, inplace=True)               \n",
    "    dataset[\"BsmtFinSF2\"].fillna(0, inplace=True)               \n",
    "    dataset[\"BsmtUnfSF\"].fillna(0, inplace=True)                \n",
    "    dataset[\"TotalBsmtSF\"].fillna(0, inplace=True)\n",
    "    dataset[\"BsmtFinType1\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"BsmtFinType2\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"BsmtFullBath\"].fillna(0, inplace=True)\n",
    "    dataset[\"BsmtHalfBath\"].fillna(0, inplace=True)\n",
    "    dataset[\"BsmtQual\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # most common electrical system\n",
    "    dataset[\"Electrical\"].fillna(\"SBrkr\", inplace=True)\n",
    "\n",
    "    # one missing in test; set to other\n",
    "    dataset[\"Exterior1st\"].fillna(\"Other\", inplace=True)\n",
    "    dataset[\"Exterior2nd\"].fillna(\"Other\", inplace=True)\n",
    "\n",
    "    # no fence\n",
    "    dataset[\"Fence\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # no fireplace\n",
    "    dataset[\"FireplaceQu\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # fill with typical functionality\n",
    "    dataset[\"Functional\"].fillna(\"Typ\", inplace=True)\n",
    "\n",
    "    # no garage\n",
    "    dataset[\"GarageArea\"].fillna(0, inplace=True)\n",
    "    dataset[\"GarageCars\"].fillna(0, inplace=True)\n",
    "    dataset[\"GarageCond\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"GarageFinish\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"GarageQual\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"GarageType\"].fillna(\"None\", inplace=True)\n",
    "    dataset[\"GarageYrBlt\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # \"typical\" kitchen\n",
    "    dataset[\"KitchenQual\"].fillna(\"TA\", inplace=True)\n",
    "\n",
    "    # lot frontage (no explanation for NA values, perhaps no frontage)\n",
    "    dataset[\"LotFrontage\"].fillna(0, inplace=True)\n",
    "\n",
    "    # Masonry veneer (no explanation for NA values, perhaps no masonry veneer)\n",
    "    dataset[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "    dataset[\"MasVnrType\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # most common value\n",
    "    dataset[\"MSZoning\"].fillna(\"RL\", inplace=True)\n",
    "\n",
    "    # no misc features\n",
    "    dataset[\"MiscFeature\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "    # description says NA = no pool, but there are entries with PoolArea >0 and PoolQC = NA. Fill the ones with values with average condition\n",
    "    dataset.loc[(dataset['PoolQC'].isnull()) & (dataset['PoolArea']==0), 'PoolQC' ] = 'None'\n",
    "    dataset.loc[(dataset['PoolQC'].isnull()) & (dataset['PoolArea']>0), 'PoolQC' ] = 'TA'\n",
    "\n",
    "    # classify missing SaleType as other\n",
    "    dataset[\"SaleType\"].fillna(\"WD\", inplace=True)\n",
    "\n",
    "    # most common\n",
    "    dataset[\"Utilities\"].fillna(\"AllPub\", inplace=True)\n",
    "\n",
    "    \n",
    "    ### feature engineering ###\n",
    "    # create new binary variables: assign 1 to mode\n",
    "#     dataset[\"IsRegularLotShape\"] = (dataset[\"LotShape\"] == \"Reg\") * 1\n",
    "#     dataset[\"IsLandLevel\"] = (dataset[\"LandContour\"] == \"Lvl\") * 1\n",
    "#     dataset[\"IsLandSlopeGentle\"] = (dataset[\"LandSlope\"] == \"Gtl\") * 1\n",
    "#     dataset[\"IsElectricalSBrkr\"] = (dataset[\"Electrical\"] == \"SBrkr\") * 1\n",
    "#     dataset[\"IsGarageDetached\"] = (dataset[\"GarageType\"] == \"Detchd\") * 1\n",
    "#     dataset[\"IsPavedDrive\"] = (dataset[\"PavedDrive\"] == \"Y\") * 1\n",
    "#     dataset[\"HasShed\"] = (dataset[\"MiscFeature\"] == \"Shed\") * 1\n",
    "    # was the house remodeled? if yes, assign 1\n",
    "#     dataset[\"Remodeled\"] = (dataset[\"YearRemodAdd\"] != dataset[\"YearBuilt\"]) * 1\n",
    "    # assign 1 to houses which were sold the same year they were remodeled\n",
    "#     dataset[\"RecentRemodel\"] = (dataset[\"YearRemodAdd\"] == dataset[\"YrSold\"]) * 1\n",
    "    # assign 1 to houses which were sold the same year they were built\n",
    "#     dataset[\"VeryNewHouse\"] = (dataset[\"YearBuilt\"] == dataset[\"YrSold\"]) * 1\n",
    "\n",
    "    \n",
    "    ### normalization ###\n",
    "    # normalize distribution for continuous variables with skew > 3\n",
    "    continuous_vars = ['1stFlrSF', '2ndFlrSF', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'EnclosedPorch',\\\n",
    "                'GarageArea', 'GrLivArea', 'LotArea', 'LotFrontage', 'MasVnrArea', 'MiscVal',\\\n",
    "                'OpenPorchSF', 'PoolArea', 'ScreenPorch', 'TotalBsmtSF', 'WoodDeckSF']\n",
    "    skew_threshold = 3\n",
    "    for entry in continuous_vars:\n",
    "        if dataset[entry].skew() > skew_threshold:\n",
    "            dataset[entry] = np.log1p(dataset[entry])\n",
    "    \n",
    "    \n",
    "    ### standardization ###\n",
    "    # standardization for continuous variables\n",
    "    sub_df = dataset[continuous_vars]\n",
    "    array_standard = StandardScaler().fit_transform(sub_df)\n",
    "    df_standard = pd.DataFrame(array_standard, dataset.index, continuous_vars)\n",
    "    dataset.drop(dataset[continuous_vars], axis=1, inplace=True)\n",
    "    dataset = pd.concat([dataset, df_standard], axis=1)\n",
    "    \n",
    "    \n",
    "    ### dummies ###\n",
    "    # split back to training and test set\n",
    "    df_train_len = len(df_train)\n",
    "    df_dummies =  pd.get_dummies(dataset)\n",
    "    df_train = df_dummies[:df_train_len]\n",
    "    df_test = df_dummies[df_train_len:]\n",
    "\n",
    "    return df_train, df_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/voshkanov/house-prices-datasets/train.csv', index_col='Id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/home/voshkanov/house-prices-datasets/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of Id\n",
       "1        WD\n",
       "2        WD\n",
       "3        WD\n",
       "4        WD\n",
       "5        WD\n",
       "6        WD\n",
       "7        WD\n",
       "8        WD\n",
       "9        WD\n",
       "10       WD\n",
       "11       WD\n",
       "12      New\n",
       "13       WD\n",
       "14      New\n",
       "15       WD\n",
       "16       WD\n",
       "17       WD\n",
       "18       WD\n",
       "19       WD\n",
       "20      COD\n",
       "21      New\n",
       "22       WD\n",
       "23       WD\n",
       "24       WD\n",
       "25       WD\n",
       "26       WD\n",
       "27       WD\n",
       "28       WD\n",
       "29       WD\n",
       "30       WD\n",
       "       ... \n",
       "1431     WD\n",
       "1432     WD\n",
       "1433     WD\n",
       "1434     WD\n",
       "1435     WD\n",
       "1436    COD\n",
       "1437     WD\n",
       "1438    New\n",
       "1439     WD\n",
       "1440     WD\n",
       "1441     WD\n",
       "1442     WD\n",
       "1443     WD\n",
       "1444     WD\n",
       "1445     WD\n",
       "1446     WD\n",
       "1447     WD\n",
       "1448     WD\n",
       "1449     WD\n",
       "1450     WD\n",
       "1451     WD\n",
       "1452    New\n",
       "1453     WD\n",
       "1454     WD\n",
       "1455     WD\n",
       "1456     WD\n",
       "1457     WD\n",
       "1458     WD\n",
       "1459     WD\n",
       "1460     WD\n",
       "Name: SaleType, Length: 1460, dtype: object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"SaleType\"].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, y_train = preprocessing(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mapper = DataFrameMapper([(['LotConfig'], pp.LabelBinarizer()),\n",
    "                          (['MSSubClass'], pp.MinMaxScaler()),\n",
    "                          (['LotFrontage'], pp.MinMaxScaler()),\n",
    "                          (['MSZoning'], pp.LabelBinarizer()),\n",
    "                          (['LotArea'], pp.MinMaxScaler()),\n",
    "                          (['Street'], pp.LabelBinarizer()),\n",
    "                          (['Utilities'], pp.LabelBinarizer()),\n",
    "                          (['Alley'], pp.LabelBinarizer()),\n",
    "                          (['LotShape'], pp.LabelBinarizer()),\n",
    "                          (['LandContour'], pp.LabelBinarizer()),\n",
    "                          (['Neighborhood'], pp.OrdinalEncoder()),\n",
    "                          (['LotConfig'], pp.LabelBinarizer()),\n",
    "                          (['LandSlope'], pp.LabelBinarizer()),\n",
    "                          (['Condition1'], pp.LabelBinarizer()),\n",
    "                          (['Condition2'], pp.LabelBinarizer()),\n",
    "                          (['BldgType'], pp.LabelBinarizer()),\n",
    "                          (['HouseStyle'], pp.LabelBinarizer()),\n",
    "                          (['OverallQual'], pp.StandardScaler()),\n",
    "                          (['OverallCond'], pp.MinMaxScaler()),\n",
    "                          (['YearBuilt'], pp.MinMaxScaler()),\n",
    "                          (['YearRemodAdd'], pp.MinMaxScaler()),\n",
    "                          (['RoofStyle'], pp.LabelBinarizer()),\n",
    "                          (['RoofMatl'], pp.LabelBinarizer()),\n",
    "                          (['Exterior1st'], pp.OrdinalEncoder()),\n",
    "                          (['Exterior2nd'], pp.OrdinalEncoder()),\n",
    "                          (['MasVnrArea'], pp.MinMaxScaler()),\n",
    "                          (['MasVnrType'], pp.LabelBinarizer()),\n",
    "                          (['ExterQual'], pp.LabelBinarizer()),\n",
    "                          (['ExterCond'], pp.LabelBinarizer()),\n",
    "                          (['Foundation'], pp.LabelBinarizer()),\n",
    "                          (['BsmtQual'], pp.LabelBinarizer()),\n",
    "                          (['BsmtCond'], pp.LabelBinarizer()),\n",
    "                          (['BsmtExposure'], pp.LabelBinarizer()),\n",
    "                          (['BsmtFinType1'], pp.LabelBinarizer()),\n",
    "                          (['BsmtFinSF1'], pp.MinMaxScaler()),\n",
    "                          (['BsmtFinType2'], pp.LabelBinarizer()),\n",
    "                          (['BsmtFinSF2'], pp.MinMaxScaler()),\n",
    "                          (['BsmtUnfSF'], pp.MinMaxScaler()),\n",
    "                          (['TotalBsmtSF'], pp.StandardScaler()),\n",
    "                          (['Heating'], pp.LabelBinarizer()),\n",
    "                          (['HeatingQC'], pp.LabelBinarizer()),\n",
    "                          (['CentralAir'], pp.LabelBinarizer()),\n",
    "                          (['Electrical'], pp.LabelBinarizer()),\n",
    "                          (['1stFlrSF'], pp.StandardScaler()),\n",
    "                          (['2ndFlrSF'], pp.MinMaxScaler()),\n",
    "                          (['LowQualFinSF'], pp.MinMaxScaler()),\n",
    "                          (['GrLivArea'], pp.StandardScaler()),\n",
    "                          (['BsmtFullBath'], pp.MinMaxScaler()),\n",
    "                          (['BsmtHalfBath'], pp.MinMaxScaler()),\n",
    "                          (['FullBath'], pp.MinMaxScaler()),\n",
    "                          (['HalfBath'], pp.MinMaxScaler()),\n",
    "                          (['BedroomAbvGr'], pp.MinMaxScaler()),\n",
    "                          (['KitchenAbvGr'], pp.MinMaxScaler()),\n",
    "                          (['KitchenQual'], pp.LabelBinarizer()),\n",
    "                          (['TotRmsAbvGrd'], pp.MinMaxScaler()),\n",
    "                          (['Functional'], pp.LabelBinarizer()),\n",
    "                          (['Fireplaces'], pp.MinMaxScaler()),\n",
    "                          (['FireplaceQu'], pp.LabelBinarizer()),\n",
    "                          (['GarageType'], pp.LabelBinarizer()),\n",
    "                          (['GarageYrBlt'], pp.MinMaxScaler()),\n",
    "                          (['GarageFinish'], pp.LabelBinarizer()),\n",
    "                          (['GarageCars'], pp.MinMaxScaler()),\n",
    "                          (['GarageArea'], pp.StandardScaler()),\n",
    "                          (['GarageQual'], pp.LabelBinarizer()),\n",
    "                          (['GarageCond'], pp.LabelBinarizer()),\n",
    "                          (['PavedDrive'], pp.LabelBinarizer()),\n",
    "                          (['WoodDeckSF'], pp.MinMaxScaler()),\n",
    "                          (['OpenPorchSF'], pp.MinMaxScaler()),\n",
    "                          (['EnclosedPorch'], pp.MinMaxScaler()),\n",
    "                          (['3SsnPorch'], pp.MinMaxScaler()),\n",
    "                          (['ScreenPorch'], pp.MinMaxScaler()),\n",
    "                          (['PoolArea'], pp.MinMaxScaler()),\n",
    "                          (['PoolQC'], pp.LabelBinarizer()),\n",
    "                          (['Fence'], pp.LabelBinarizer()),\n",
    "                          (['MiscFeature'], pp.LabelBinarizer()),\n",
    "                          (['MiscVal'], pp.MinMaxScaler()),\n",
    "                          (['MoSold'], pp.MinMaxScaler()),\n",
    "                          (['YrSold'], pp.MinMaxScaler()),\n",
    "                          (['SaleType'], pp.LabelBinarizer()),\n",
    "                          (['SaleCondition'], pp.LabelBinarizer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data = mapper.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/voshkanov/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14047.964865362665"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = LassoCV(eps=10**-7, n_alphas=75)\n",
    "model.fit(X_train, y_train)\n",
    "result = model.predict(X_test)\n",
    "\n",
    "mean_absolute_error(np.expm1(result), np.expm1(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = mapper.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.98976006, 12.07139589, 12.44466268, 12.02886759, 11.4148108 ,\n",
       "       11.59907844, 11.57922795, 11.85731117, 12.39863497, 12.03316082,\n",
       "       12.65034119, 12.22069645, 11.97514158, 11.6527397 , 11.54366217,\n",
       "       11.64905706, 11.995924  , 11.90949666, 12.34606891, 13.49440151,\n",
       "       12.03102659, 11.72289228, 11.34400545, 11.71030595, 12.75363082,\n",
       "       12.28364988, 12.05252577, 11.94937929, 11.65385206, 12.30679039,\n",
       "       11.99753528, 12.34324024, 12.38127777, 11.83412295, 11.8348353 ,\n",
       "       11.52847727, 12.31781581, 12.33039833, 12.4810971 , 12.0053547 ,\n",
       "       12.54818474, 12.35789385, 12.33341977, 12.22715106, 11.31691599,\n",
       "       11.93464791, 11.66880756, 12.21826317, 11.63383609, 11.78105916,\n",
       "       11.29244964, 12.40283706, 12.57816988, 11.85532445, 12.34727073,\n",
       "       12.28499675, 12.40721011, 12.07748688, 11.80828592, 11.94780815,\n",
       "       11.82366422, 12.40781534, 11.42230052, 12.06646209, 12.08822316,\n",
       "       11.6118051 , 11.7597301 , 11.88415288, 12.19567544, 11.61683276,\n",
       "       11.9102935 , 12.02166723, 12.30737118, 12.43196546, 12.40562214,\n",
       "       11.66495587, 12.78541871, 11.43341157, 12.14835613, 11.80822294,\n",
       "       11.62635815, 11.60414829, 12.14091777, 11.94833449, 11.93630934,\n",
       "       11.97409597, 11.97665827, 11.52450776, 11.565142  , 12.04834863,\n",
       "       11.77882634, 11.85089127, 11.71840324, 12.15079249, 11.95204129,\n",
       "       11.76211419, 11.78661145, 11.62624754, 11.8468764 , 11.69491743,\n",
       "       11.70095335, 12.24667237, 11.19877881, 12.00900683, 12.01609293,\n",
       "       11.70619213, 11.50320311, 12.15777479, 11.78594584, 12.26909638,\n",
       "       11.85576973, 11.71945546, 12.42585015, 11.55676397, 12.60599523,\n",
       "       11.70981174, 12.60958651, 12.21328355, 12.47003436, 12.52678808,\n",
       "       11.62917318, 11.57317735, 11.95890442, 11.75000751, 11.88192172,\n",
       "       11.97266601, 12.34782216, 12.45337879, 12.55232531, 12.2505894 ,\n",
       "       11.92071035, 11.50184925, 11.82058291, 11.6199298 , 11.72336394,\n",
       "       11.69311094, 11.78562737, 12.69722806, 11.847652  , 12.50588049,\n",
       "       11.80477923, 11.88584621, 11.80388309, 12.02800856, 11.2847499 ,\n",
       "       11.84297836, 12.16312441, 12.22209963, 11.72967458, 11.63817302,\n",
       "       12.06546457, 11.65759293, 11.99930121, 12.65922793, 12.29533563,\n",
       "       11.76958958, 11.65418504, 12.2100605 , 12.07423069, 12.22324038,\n",
       "       11.88468837, 11.82515918, 11.98041697, 11.62612632, 12.80325453,\n",
       "       11.87719058, 11.6371287 , 11.85291998, 12.07767111, 12.41895127,\n",
       "       12.27867476, 12.3340676 , 12.31833369, 11.12069811, 12.0389222 ,\n",
       "       12.40389711, 12.08345318, 11.84872405, 11.61021448, 12.19592873,\n",
       "       12.45113152, 12.18868216, 11.59788271, 11.88529402, 11.88175947,\n",
       "       12.14722232, 11.38903051, 11.95851665, 12.62157414, 12.10427364,\n",
       "       12.05124155, 12.40123637, 12.41205901, 12.09437533, 12.33687763,\n",
       "       11.49242773, 11.9290816 , 12.40569545, 11.21928576, 12.15682864,\n",
       "       12.25366701, 12.2805651 , 12.00437772, 11.94962531, 12.09219489,\n",
       "       12.29065666, 11.88445508, 12.57192701, 12.2385259 , 12.73168738,\n",
       "       12.05662532, 11.69432259, 11.97622916, 11.96403069, 12.3915674 ,\n",
       "       11.99090989, 12.85162582, 11.82320985, 11.89019685, 11.79689116,\n",
       "       11.99741442, 12.03056636, 11.66110155, 12.13837089, 12.22324231,\n",
       "       12.52606582, 11.84256579, 13.08021663, 11.82466583, 12.49634193,\n",
       "       12.14467772, 12.48800416, 12.44276946, 12.15813145, 12.50234087,\n",
       "       12.41118241, 11.94536407, 10.79631541, 12.1518581 , 11.74295359,\n",
       "       11.70306072, 12.78148247, 12.00048067, 12.18143082, 11.52987342,\n",
       "       12.18164014, 11.92906079, 11.81629913, 12.31913517, 12.45082073,\n",
       "       12.6782824 , 12.03444573, 11.90729202, 12.40002075, 11.48124604,\n",
       "       12.46781129, 11.73079406, 11.57121862, 11.96766341, 11.98782555,\n",
       "       12.43445312, 11.96901164, 11.83644502, 11.65049921, 11.79273548,\n",
       "       11.87581926, 12.45192333, 11.61570076, 11.81507267, 12.18263475,\n",
       "       12.06203174, 11.76029459, 11.44467765, 12.76391575, 12.05971517,\n",
       "       11.79871707, 12.60878123, 12.20504207, 11.71454883, 12.27898759,\n",
       "       12.17761384, 12.36551989, 12.28968652, 12.24474998, 11.72415512,\n",
       "       12.47595135, 12.81947802, 11.99584065, 11.94365272, 12.2256777 ,\n",
       "       11.77136339, 11.73726234])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-371d9141b38d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SalePrice\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"Id\": df_test.index.values, \"SalePrice\": np.expm1(result)})\n",
    "submission.to_csv('result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
